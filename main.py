# ---------- znt-GPT  main.py -- import & ç¯å¢ƒä¿®è¡¥ ----------
import os, sys, importlib, types, builtins
os.environ["STREAMLIT_WATCHER_TYPE"] = "none"          # å…³æ‰æºç ç›‘æ§åå°çº¿ç¨‹
builtins.__dict__["__torch_fake_module__"] = True      # é¿å… torch å»¶è¿ŸåŠ è½½æ—¶å†æŠ¥é”™

# â‘  å½»åº•ç¦ç”¨ Streamlit å¯¹æ¨¡å—è·¯å¾„çš„æ¢æµ‹
import streamlit.watcher.local_sources_watcher as _sw
_sw.LocalSourcesWatcher._get_module_paths = lambda *_a, **_k: []

# â‘¡ ä¿®è¡¥ torch.*
try:
    torch = importlib.import_module("torch")

    def _patch(name: str):
        """ä¸º torch.(classes|_classes) æ‰“è¡¥ä¸ï¼šmock __getattr__ & __path__"""
        mod = getattr(torch, name, None)
        if not mod:
            return
        # (a) è®©ä»»ä½• getattr è°ƒç”¨éƒ½è¿”å›ä¸€ä¸ªå“‘å¯¹è±¡ï¼Œé¿å… _get_custom_class_python_wrapper
        mod.__getattr__ = lambda *_, **__: types.SimpleNamespace()         # type: ignore
        # (b) ä¼ªé€  __path__ï¼Œé˜²æ­¢ __path__._path AttributeError
        if not getattr(mod, "__path__", None):
            class _FakePath(list): _path = []
            mod.__path__ = _FakePath()                                     # type: ignore

    _patch("_classes")
    _patch("classes")
except Exception:
    pass
# -----------------------------------------------------------------

# â‘¢ å…¶ä½™æ­£å¸¸ importï¼ˆä¿æŒä¸å˜ï¼‰
# ---------- znt-GPT  main.py  (imports & ç¯å¢ƒè¡¥ä¸) ----------
import os, sys, types, importlib, builtins
os.environ["STREAMLIT_WATCHER_TYPE"] = "none"      # å½»åº•å…³é—­æºç çƒ­é‡è½½çº¿ç¨‹
builtins.__dict__["__torch_fake_module__"] = True  # é…åˆ torch å»¶è¿ŸåŠ è½½

# 0ï¸âƒ£   æŠŠ "ä¼ª torch.{_classes, classes}" å…ˆè¡Œæ³¨å…¥ sys.modules
def _make_fake_torch_branch(name: str):
    fake = types.ModuleType(name)
    class _FakePath(list):         # è®© watcher èƒ½å–åˆ° ._path
        _path: list = []
    fake.__path__ = _FakePath()    # type: ignore
    fake.__getattr__ = lambda *a, **k: types.SimpleNamespace()   # å“‘å“åº”
    sys.modules[name] = fake

for _n in ("torch.classes", "torch._classes"):
    if _n not in sys.modules:
        _make_fake_torch_branch(_n)

# 1ï¸âƒ£   ç¦æ‰ Streamlit å¯¹æºç çš„è·¯å¾„æ‰«æ
import streamlit.watcher.local_sources_watcher as _sw
_sw.LocalSourcesWatcher._get_module_paths = lambda *_a, **_k: []

# 2ï¸âƒ£   ç°åœ¨å†æ­£å¸¸ import torchï¼Œå¹¶æŠŠçœŸæ¨¡å—ä¹Ÿæ‰“è¡¥ä¸ï¼ˆç¨³å¦¥èµ·è§ï¼‰
try:
    torch = importlib.import_module("torch")
    for _n in ("classes", "_classes"):
        br = getattr(torch, _n, None)
        if br:
            br.__getattr__ = lambda *a, **k: types.SimpleNamespace()  # type: ignore
            if not getattr(br, "__path__", None):
                class _FakePath2(list): _path = []
                br.__path__ = _FakePath2()                            # type: ignore
except Exception:
    # torch å¯èƒ½æ ¹æœ¬ç”¨ä¸åˆ°ï¼›å¿½ç•¥å³å¯
    pass
# -----------------------------------------------------------------

# 3ï¸âƒ£   å…¶ä½™å¸¸è§„ import
import pysqlite3
sys.modules["sqlite3"] = pysqlite3

import pathlib, asyncio, streamlit as st
from langchain_openai import ChatOpenAI
import nest_asyncio
nest_asyncio.apply()

from utils import get_chat_response, online_search_agent
from ingest import ingest_folder
from memory import MemoryManager
# ----------  import è¡¥ä¸ç»“æŸ --------------------------------------
# ---------- å¤´éƒ¨ç»“æŸ --------------------------------------------



# é¡µé¢é…ç½®
st.set_page_config(page_title="znt-GPT", page_icon="ğŸ¤–", layout="wide")
st.markdown("""
    <style>
      .stChatMessage { font-size:20px !important; }
      textarea, input { font-size:18px !important; }
    </style>
""", unsafe_allow_html=True)

# ç™½åå• & å‘é‡åº“æ ¹ç›®å½•
WHITE_LIST = {"èµµé»æ¶›", "å´é›¨é˜³", "åæ¸…é’Ÿ", "å¤§å®¶çš„çˆ¸çˆ¸88", "èµµå¾·èƒœ", "å´æ±‰æ˜“"}
BASE_DB_DIR = pathlib.Path("vector_dbs")
BASE_DB_DIR.mkdir(exist_ok=True)

# Session state åˆå§‹åŒ–
st.session_state.setdefault("authenticated", False)
st.session_state.setdefault("user", None)
st.session_state.setdefault("messages", [{"role": "ai", "content": "æ‚¨å¥½ï¼è¯·åœ¨ä¸‹æ–¹è¾“å…¥é—®é¢˜ã€‚"}])
st.session_state.setdefault("uploaded_done", False)

# ç™»å½•é€»è¾‘
if not st.session_state["authenticated"]:
    st.title("ğŸ¤– znt-GPT ç™»å½•")
    name = st.text_input("è¯·è¾“å…¥ç”¨æˆ·åï¼ˆç™½åå•ï¼‰", key="login_name")
    if st.button("è¿›å…¥", key="login_btn"):
        if name in WHITE_LIST:
            st.session_state.update({"authenticated": True, "user": name})
            st.rerun()
        else:
            st.error("æŠ±æ­‰ï¼ä¸åœ¨ç™½åå•ã€‚")
    st.stop()

# ç”¨æˆ·ç›®å½•åˆå§‹åŒ–
user = st.session_state["user"]
user_db_dir = BASE_DB_DIR / user
user_db_dir.mkdir(parents=True, exist_ok=True)
st.title(f"ğŸ¤– ä½ å¥½ï¼Œ{user}ï¼")

# ä¾§è¾¹æ ï¼šAPI è®¾ç½®
with st.sidebar:
    st.header("ğŸ”§ è®¾ç½®")
    api_key = st.text_input("OpenAI API Key", type="password")
    serp_key = st.text_input("SerpAPI Keyï¼ˆè”ç½‘æœç´¢ï¼‰", type="password")
    model = st.selectbox("æ¨¡å‹", ["gpt-3.5-turbo", "gpt-4", "o3", "o4-mini", "gpt-4.1", "gpt-4.5-preview-2025-02-27"])
    api_base = st.text_input("API Base URL", value="https://api.aigc369.com/v1")

    if st.button("âœ… ä¿å­˜é…ç½®", key="setup"):
        if not api_key:
            st.warning("è¯·å¡«å†™ OpenAI Key")
            st.stop()
        st.session_state.update({
            "openai_api_key": api_key,
            "serp_api_key": serp_key,
            "model_name": model,
            "api_base": api_base
        })

        # åˆå§‹åŒ– LLM å’Œè®°å¿†ç®¡ç†å™¨
        summary_llm = ChatOpenAI(
            model=model,
            openai_api_key=api_key,
            openai_api_base=api_base
        )
        # åˆ›å»ºè®°å¿†ç®¡ç†å™¨ï¼ŒåŒ…å«çŸ­æœŸå’Œé•¿æœŸè®°å¿†ï¼Œä½¿ç”¨ç”¨æˆ·ç‰¹å®šçš„å‘é‡å­˜å‚¨è·¯å¾„
        memory_vector_path = str(user_db_dir / "memory_vectors")
        st.session_state["memory_manager"] = MemoryManager(
            summary_llm,
            vector_store_path=memory_vector_path
        )

        st.success("é…ç½®å®Œæˆï¼")
        st.rerun()

# ç­‰å¾…é…ç½®å®Œæˆ
if "openai_api_key" not in st.session_state or "memory_manager" not in st.session_state:
    st.info("è¯·åœ¨ä¾§è¾¹æ å®Œæˆé…ç½®åå†ä½¿ç”¨")
    st.stop()

# å¯é€‰è°ƒè¯•ï¼šæŸ¥çœ‹å†å²æ‘˜è¦å†…å®¹
#with st.sidebar:
#    if st.button("ğŸ“„ æŸ¥çœ‹å†å²æ‘˜è¦"):
#        if "memory_manager" in st.session_state:
#            short_term = st.session_state["memory_manager"].short_term.memory.buffer
#            st.sidebar.subheader("çŸ­æœŸè®°å¿†")
#            st.sidebar.code(short_term)
#            
#            long_term = st.session_state["memory_manager"].get_long_term_summary()
#            st.sidebar.subheader("é•¿æœŸè®°å¿†æ‘˜è¦")
#            st.sidebar.code(long_term)

# å±•ç¤ºèŠå¤©è®°å½•
for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).write(msg["content"])

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
with st.container():
    uploaded = st.file_uploader(
        "ğŸ“¥ æ‹–æ–‡æ¡£/å›¾ç‰‡åˆ°æ­¤å¤„", type=["pdf", "docx", "pptx", "png", "jpg"],
        accept_multiple_files=True, key="uploader"
    )
    if uploaded and not st.session_state["uploaded_done"]:
        with st.spinner("è§£æå¹¶å†™å…¥å‘é‡åº“â€¦"):
            try:
                upload_dir = user_db_dir / "uploads"
                upload_dir.mkdir(exist_ok=True)
                for f in uploaded:
                    with open(upload_dir / f.name, "wb") as w:
                        w.write(f.getbuffer())
                ingest_folder(str(upload_dir), persist_dir=str(user_db_dir))
                st.success(f"å·²å†™å…¥ {len(uploaded)} ä¸ªæ–‡ä»¶ï¼")
                st.session_state["uploaded_done"] = True
                st.rerun()
            except Exception as e:
                st.error(f"æ–‡ä»¶å¤„ç†å‡ºé”™ï¼š{e}")

# èŠå¤©è¾“å…¥ä¸å¼€å…³
col1, col2 = st.columns(2)
online = col1.checkbox("ğŸŒ è”ç½‘æœç´¢", key="online")
cot = col2.checkbox("ğŸ§  æ·±åº¦æ€è€ƒ", key="cot")
prompt = st.chat_input("è¯·è¾“å…¥å†…å®¹ï¼ˆå›è½¦å‘é€ï¼‰")

# å“åº”é€»è¾‘
if prompt:
    st.session_state["messages"].append({"role": "human", "content": prompt})
    st.chat_message("human").write(prompt)
    with st.spinner("AIæ€è€ƒä¸­â€¦"):
        try:
            if online:
                if not st.session_state.get("serp_api_key"):
                    raise ValueError("è¯·åœ¨ä¾§è¾¹æ å¡«å†™ SerpAPI Key")
                agent = online_search_agent(
                    openai_key=st.session_state["openai_api_key"],
                    serp_key=st.session_state["serp_api_key"],
                    model_name=st.session_state["model_name"],
                    api_base=st.session_state["api_base"]
                )
                answer = agent.invoke({"input": prompt})["output"]
            else:
                answer = get_chat_response(
                    prompt=prompt,
                    memory_manager=st.session_state["memory_manager"],
                    openai_api_key=st.session_state["openai_api_key"],
                    model_name=st.session_state["model_name"],
                    use_docs=True,
                    embed_dir=str(user_db_dir),
                    chain_of_thought=cot,
                    api_base=st.session_state["api_base"]
                )
        except Exception as ex:
            answer = f"å‡ºé”™ï¼š{ex}"
    st.session_state["messages"].append({"role": "ai", "content": answer})
    st.chat_message("ai").write(answer)