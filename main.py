# main.py  â€” znt-GPT ä¸»å…¥å£
import sys
import os
os.environ["STREAMLIT_WATCHER_TYPE"] = "none"
import builtins
builtins.__dict__["__torch_fake_module__"] = True
# å¼ºåˆ¶ä¸­æ­¢æºè·¯å¾„ç›‘æ§å™¨ï¼ˆå¯é€‰è¡¥æ•‘ï¼‰
import streamlit.watcher.local_sources_watcher as watcher
watcher.LocalSourcesWatcher._get_module_paths = lambda self, module: []
import pysqlite3
sys.modules["sqlite3"] = pysqlite3
import pathlib
import asyncio
import streamlit as st
from langchain_openai import ChatOpenAI
import nest_asyncio
nest_asyncio.apply()

from utils import get_chat_response, online_search_agent
from ingest import ingest_folder
from memory import MemoryManager


# é¡µé¢é…ç½®
st.set_page_config(page_title="znt-GPT", page_icon="ğŸ¤–", layout="wide")
st.markdown("""
    <style>
      .stChatMessage { font-size:20px !important; }
      textarea, input { font-size:18px !important; }
    </style>
""", unsafe_allow_html=True)

# ç™½åå• & å‘é‡åº“æ ¹ç›®å½•
WHITE_LIST = {"èµµé»æ¶›", "å´é›¨é˜³", "åæ¸…é’Ÿ", "å¤§å®¶çš„çˆ¸çˆ¸88", "èµµå¾·èƒœ", "å´æ±‰æ˜“"}
BASE_DB_DIR = pathlib.Path("vector_dbs")
BASE_DB_DIR.mkdir(exist_ok=True)

# Session state åˆå§‹åŒ–
st.session_state.setdefault("authenticated", False)
st.session_state.setdefault("user", None)
st.session_state.setdefault("messages", [{"role": "ai", "content": "æ‚¨å¥½ï¼è¯·åœ¨ä¸‹æ–¹è¾“å…¥é—®é¢˜ã€‚"}])
st.session_state.setdefault("uploaded_done", False)

# ç™»å½•é€»è¾‘
if not st.session_state["authenticated"]:
    st.title("ğŸ¤– znt-GPT ç™»å½•")
    name = st.text_input("è¯·è¾“å…¥ç”¨æˆ·åï¼ˆç™½åå•ï¼‰", key="login_name")
    if st.button("è¿›å…¥", key="login_btn"):
        if name in WHITE_LIST:
            st.session_state.update({"authenticated": True, "user": name})
            st.rerun()
        else:
            st.error("æŠ±æ­‰ï¼ä¸åœ¨ç™½åå•ã€‚")
    st.stop()

# ç”¨æˆ·ç›®å½•åˆå§‹åŒ–
user = st.session_state["user"]
user_db_dir = BASE_DB_DIR / user
user_db_dir.mkdir(parents=True, exist_ok=True)
st.title(f"ğŸ¤– ä½ å¥½ï¼Œ{user}ï¼")

# ä¾§è¾¹æ ï¼šAPI è®¾ç½®
with st.sidebar:
    st.header("ğŸ”§ è®¾ç½®")
    api_key = st.text_input("OpenAI API Key", type="password")
    serp_key = st.text_input("SerpAPI Keyï¼ˆè”ç½‘æœç´¢ï¼‰", type="password")
    model = st.selectbox("æ¨¡å‹", ["gpt-3.5-turbo", "gpt-4", "o3", "o4-mini", "gpt-4.1", "gpt-4.5-preview-2025-02-27"])
    api_base = st.text_input("API Base URL", value="https://api.aigc369.com/v1")

    if st.button("âœ… ä¿å­˜é…ç½®", key="setup"):
        if not api_key:
            st.warning("è¯·å¡«å†™ OpenAI Key")
            st.stop()
        st.session_state.update({
            "openai_api_key": api_key,
            "serp_api_key": serp_key,
            "model_name": model,
            "api_base": api_base
        })

        # åˆå§‹åŒ– LLM å’Œè®°å¿†ç®¡ç†å™¨
        summary_llm = ChatOpenAI(
            model=model,
            openai_api_key=api_key,
            openai_api_base=api_base
        )
        # åˆ›å»ºè®°å¿†ç®¡ç†å™¨ï¼ŒåŒ…å«çŸ­æœŸå’Œé•¿æœŸè®°å¿†ï¼Œä½¿ç”¨ç”¨æˆ·ç‰¹å®šçš„å‘é‡å­˜å‚¨è·¯å¾„
        memory_vector_path = str(user_db_dir / "memory_vectors")
        st.session_state["memory_manager"] = MemoryManager(
            summary_llm,
            vector_store_path=memory_vector_path
        )

        st.success("é…ç½®å®Œæˆï¼")
        st.rerun()

# ç­‰å¾…é…ç½®å®Œæˆ
if "openai_api_key" not in st.session_state or "memory_manager" not in st.session_state:
    st.info("è¯·åœ¨ä¾§è¾¹æ å®Œæˆé…ç½®åå†ä½¿ç”¨")
    st.stop()

# å¯é€‰è°ƒè¯•ï¼šæŸ¥çœ‹å†å²æ‘˜è¦å†…å®¹
with st.sidebar:
    if st.button("ğŸ“„ æŸ¥çœ‹å†å²æ‘˜è¦"):
        if "memory_manager" in st.session_state:
            short_term = st.session_state["memory_manager"].short_term.memory.buffer
            st.sidebar.subheader("çŸ­æœŸè®°å¿†")
            st.sidebar.code(short_term)
            
            long_term = st.session_state["memory_manager"].get_long_term_summary()
            st.sidebar.subheader("é•¿æœŸè®°å¿†æ‘˜è¦")
            st.sidebar.code(long_term)

# å±•ç¤ºèŠå¤©è®°å½•
for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).write(msg["content"])

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
with st.container():
    uploaded = st.file_uploader(
        "ğŸ“¥ æ‹–æ–‡æ¡£/å›¾ç‰‡åˆ°æ­¤å¤„", type=["pdf", "docx", "pptx", "png", "jpg"],
        accept_multiple_files=True, key="uploader"
    )
    if uploaded and not st.session_state["uploaded_done"]:
        with st.spinner("è§£æå¹¶å†™å…¥å‘é‡åº“â€¦"):
            try:
                upload_dir = user_db_dir / "uploads"
                upload_dir.mkdir(exist_ok=True)
                for f in uploaded:
                    with open(upload_dir / f.name, "wb") as w:
                        w.write(f.getbuffer())
                ingest_folder(str(upload_dir), persist_dir=str(user_db_dir))
                st.success(f"å·²å†™å…¥ {len(uploaded)} ä¸ªæ–‡ä»¶ï¼")
                st.session_state["uploaded_done"] = True
                st.rerun()
            except Exception as e:
                st.error(f"æ–‡ä»¶å¤„ç†å‡ºé”™ï¼š{e}")

# èŠå¤©è¾“å…¥ä¸å¼€å…³
col1, col2 = st.columns(2)
online = col1.checkbox("ğŸŒ è”ç½‘æœç´¢", key="online")
cot = col2.checkbox("ğŸ§  æ·±åº¦æ€è€ƒ", key="cot")
prompt = st.chat_input("è¯·è¾“å…¥å†…å®¹ï¼ˆå›è½¦å‘é€ï¼‰")

# å“åº”é€»è¾‘
if prompt:
    st.session_state["messages"].append({"role": "human", "content": prompt})
    st.chat_message("human").write(prompt)
    with st.spinner("AIæ€è€ƒä¸­â€¦"):
        try:
            if online:
                if not st.session_state.get("serp_api_key"):
                    raise ValueError("è¯·åœ¨ä¾§è¾¹æ å¡«å†™ SerpAPI Key")
                agent = online_search_agent(
                    openai_key=st.session_state["openai_api_key"],
                    serp_key=st.session_state["serp_api_key"],
                    model_name=st.session_state["model_name"],
                    api_base=st.session_state["api_base"]
                )
                answer = agent.invoke({"input": prompt})["output"]
            else:
                answer = get_chat_response(
                    prompt=prompt,
                    memory_manager=st.session_state["memory_manager"],
                    openai_api_key=st.session_state["openai_api_key"],
                    model_name=st.session_state["model_name"],
                    use_docs=True,
                    embed_dir=str(user_db_dir),
                    chain_of_thought=cot,
                    api_base=st.session_state["api_base"]
                )
        except Exception as ex:
            answer = f"å‡ºé”™ï¼š{ex}"
    st.session_state["messages"].append({"role": "ai", "content": answer})
    st.chat_message("ai").write(answer)